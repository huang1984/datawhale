
### Task5 神经网络基础 

本次作业目的主要是了解神经网络基础并进行总结。主要关注以下1、2、3、4点。

1. 前馈神经网络、网络层数、输入层、隐藏层、输出层、隐藏单元、激活函数的概念。 

2. 感知机相关；利用tensorflow等工具定义简单的几层网络（激活函数sigmoid），递归使用链式法则来实现反向传播。

3. 激活函数的种类以及各自的提出背景、优缺点。（和线性模型对比，线性模型的局限性，去线性化）

4. 深度学习中的正则化（参数范数惩罚：L1正则化、L2正则化；数据集增强；噪声添加；early stop；Dropout层）、正则化的介绍。

5. 深度模型中的优化：参数初始化策略；自适应学习率算法（梯度下降、AdaGrad、RMSProp、Adam；优化算法的选择）；batch norm层（提出背景、解决什么问题、层在训练和测试阶段的计算公式）；layer norm层。

[入口](https://blog.csdn.net/zh11403070219/article/details/88388936)

[人工神经网络知识、激活函数、正则化、优化技术、Batch Normalization、Layer Normalization](https://blog.csdn.net/SMith7412/article/details/88396674)

### 前馈神经网络(FNN)

前馈神经网络（feedforward neural network），也叫作多层感知机（MLP），即包含多个隐藏层的神经网络。层与层之间是全连接的，即相邻两层的任意两个节点都有连接。

神经网络分为输入层，隐藏层和输出层。前馈网络最前面的层称作输入层，最后一层称作输出层，中间既不是输入也不是输出的层叫做隐藏层。

下图是一个3层的神经网络，输入层不计入层数。神经网络的层数表示模型的深度，正是因为这个术语才出现了“深度学习”这个名字。每一层的节点都代表一个神经元（neuron），每层神经元的个数代表了模型的宽度。![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

### 前向传播

每一个神经元以上一层各个神经元的输出作为输入，通过对各个输入的线性组合，得到带权输入，然后将计算后的带权输入作为此神经元的激活函数的输入，最终得到此神经元的激活输出值，并将激活输出值作为输入传递给下一层的神经元，如此循环传播，直到输出层。（输入层对数据不做任何处理，只负责传递数据，节点个数等于输入的维度。输出层的节点个数等于输出的维度）

首先以神经元为基本单位给出权重，偏置，带权输入，激活值的表示。然后以神经元的层为单位给出其矩阵表示(单样本)，最后给出处理多个样本时的矩阵表示。
单个神经元以神经元为基本单位给出其权重，偏置，带权输入，激活值的表示


### 反向传播

神经网络的目标是要学习到一组最优参数（！！隐层和输出层中所有神经元的权重和偏置！！）使得系统的损失函数最小，它是一种监督学习模型。在通过前向传播得到模型输出后，通过构造系统损失函数求解最优参数时，需要进行链式求导，从而形成梯度的反向传播。






### 隐藏单元（激活函数 ）

       一旦将线性分量应用于输入，将会需要应用一个非线性函数。这通过将激活函数应用于线性组合来完成。激活函数将输入信号转换为输出信号。应用激活函数后的输出看起来像 f（a *W1+ b），其中 f（）就是激活函数。

       在下图中，我们将"n"个输入给定为 X1 到 Xn 而与其相应的权重为 Wk1 到 Wkn。我们有一个给定值为 bk 的偏差。权重首先乘以与其对应的输入，然后与偏差加在一起。而这个值叫做 u。

       U =ΣW*X +b

       激活函数被应用于 u，即 f(u)，并且我们会从神经元接收最终输出，如 yk = f（u）。
![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

最常用的激活函数就是ReLU 、Sigmoid和 softmax

### Sigmoid函数

![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)
sigmoid函数（也叫逻辑斯谛函数）： 
　引用wiki百科的定义：

　　A logistic function or logistic curve is a common “S” shape (sigmoid curve).

　　其实逻辑斯谛函数也就是经常说的sigmoid函数，它的几何形状也就是一条sigmoid曲线。

![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

sigmoid将一个real value映射到（0,1）的区间（当然也可以是（-1,1）），这样可以用来做二分类。 
而softmax把一个k维的real value向量（a1,a2,a3,a4….）映射成一个（b1,b2,b3,b4….）其中bi是一个0-1的常数，然后可以根据bi的大小来进行多分类的任务，如取权重最大的一维。

sigmoid(x)=1/(1+e -x )

### 什么是正则化

　　在《Deep Learning》书中定义正则化为“对学习算法的修改——旨在减少泛化误差而不是训练误差”，《统计学习方法》中认为正则化是选择模型的一种方法。我个人比较倾向于后一种解释。在上一篇博客也提到了，模型可以看成是一个高维函数，当模型参数确定了，这个函数也就确定了。对于不同的模型参数，能得到千千万万个不同的模型，我们将这所有的可能得到的模型称之为假设空间。理想情况下，我们希望真实数据的生成过程也包括在这个假设空间中，然后我们只需要通过训练将代表该生成过程的一组模型参数找出来即可。然而，真实数据的生成过程几乎肯定在假设空间之外，我们做的事无非是从已有的假设空间中通过训练找到一个泛化能力优秀的拟合模型（即尽量匹配真实数据生成过程）。正则化可以帮助我们从假设空间中找到这样一个模型：训练误差较低，而且模型复杂度也较小。所以正则化是一种选择模型的方法。
　　正则化的作用是选择经验风险与模型复杂度同时较小的模型。在实际深度学习场景中我们几乎总是会发现，最好的拟合模型（从最小化泛化误差的意义上）是一个适当正则化的大型模型。
几种常见的正则化策略
1. 参数范数惩罚

　　参数范数惩罚通过对目标函数J
添加一个参数范数惩罚Ω(θ)，限制模型的学习能力，我们常说的L1，L2正则化就是属于这种方法。我们将正则化欧的目标函数记为J~

：
J~(θ;X,y)=J(θ;X,y)+αΩ(θ)(1)
其中α≥0是权衡范数惩罚项Ω和标准目标函数J(X;θ)相对贡献的超参数，通过调整α的大小，可以获得不同的参数选择偏好。
　　需要注意的一点是，参数包括模型中每一层仿射变换的权重和偏置，我们通常只对权重做惩罚，而不对偏置做正则惩罚。因为精确拟合偏置所需的数据通常比权重少的多，正则化偏置参数可能会导致明显的欠拟合。
　　
**L2正则化**
　　L2正则化也被称为权重衰减或岭回归，通过向目标函数添加一个L2范数平方项，使权重更加接近原点（《Deep Learning》中提到使权重接近任意特定点也有正则化效果，不过接正则化为0的情况更为常见）。L2正则化形式如下：
J~(θ;X,y)=J(θ;X,y)+α12∥w∥22(2)
下面来分析一下L2正则化能给优化过程带来什么样的效果。
　　为了简化公式，我们假设没有偏置参数，因此θ就是w，模型的总目标函数为：
J~(w;X,y)=α2wTw+J(w;X,y)
与之对应的梯度为
∇wJ~(w;X,y)=αw+∇wJ(w;X,y)(3)
使用单步梯度下降更新权重，ϵ≥0为学习率：
w←w−ϵ(αw+∇wJ(w;X,y))
换种写法就是
w←(1−ϵα)w−ϵ∇wJ(w;X,y)(4)
和没有L2正则化项的权重更新方式对比
w←w−ϵ∇wJ(w;X,y)
不难发现，在加入L2正则项之后，每次更新梯度之前，都会先对权重向量进行收缩（乘一个小于1的常数因子），这也是为什么吧L2正则化成为权重衰减的原因了。
　　接下面我们在进一步分析这种单步权重衰减的方式会给整个训练过程带来什么样的影响。我们假设没有L2正则化的情况下使目标函数取得最小训练误差时的权重向量为w∗，即w∗=argminwJ(w)。利用泰勒级数对原始目标函数在w=w∗邻域内做二次近似，有：
J(w)=J(w∗)+12(w−w∗)TH(w−w∗)(5)
其中H为w=w∗处计算的Hessian矩阵，因为w∗为最优解，所以目标函数在该点的梯度为0，所以该二次近似中没有一阶项。J(θ)的梯度为：
∇wJ(w)=H(w−w∗)
根据式(3)，加入正则化项的总的目标函数的梯度为
∇wJ~(w)=αw+H(w−w∗)(6)
现在我们记加入L2正则项之后的最优解为w~，有：
∇wJ(w~)=αw~+H(w~−w∗)=0
解得：
w~=(H+αI)−1Hw∗=(QΛQT+αI)−1QΛQTw∗=Q(Λ+αI)−1ΛQTw∗(7)

　　因为H是实对称的，可以通过特征分解将H分解为一个对角矩阵Λ和一组特征向量的标准正交基Q。至此大功告成，从式(7)可以看出，权重衰减的效果是沿着由H的特征向量所对应的轴缩放w∗，会根据缩放因子γ=λiλi+α缩放与H第i个特征向量对齐的w∗分量。
　　当α=0时，γ=1，即不加入L2正则项时，不会进行缩放；
　　当α≫λ时，γ≈0，即α越大缩放的幅度越大，最后得到的权重w越接近0；
　　当α确定，λi≪α时，γ≈0，对应的分量w∗i将会收缩到几乎为0；
　　当λi≫α时，γ≈1，对应的分量w∗i将会基本保持原来的大小。
　　从上面可以看出，每个分量的缩放程度是和特征值相关的。那么Hessian矩阵的特征值的意义是什么呢？Hessian矩阵的特征值就是形容其在该点附近特征向量方向的凹凸性，特征值越大，凸性越强。你可以把函数想想成一个小山坡，陡的那面是特征值大的方向，平缓的是特征值小的方向。而凸性和优化方法的收敛速度有关，比如梯度下降。如果正定Hessian矩阵的特征值都差不多，那么梯度下降的收敛速度越快，反之如果其特征值相差很大，那么收敛速度越慢。用大白话说就是，在能够显著减小目标函数方向上的参数会保留的相对完好，在无助于目标函数减小的方向上的参数会在训练中逐渐衰减掉。
　　关于这一点我是这么理解的，不知道对不对。目标函数下降快的方向对应于训练样本的通用的特征方向，而下降慢的方向对应于那些少数样本特有的特征方向。在上一篇博客中讲到，机器学习算法想要获得好的泛化性能，需要找到训练样本的“普遍规律”，即适用于大多数样本的特征。如果对该特征的响应进行调整，因为涉及到很多样本，所以目标函数的值变化会比较大。对于极少数样本特有的特征，即使改变其响应，对总的代价函数影响也是很微小的。所以反过来思考，如果我们改变某一特征的响应（响应大小由对应的权重分量大小控制），目标函数变化很大，那么我们就可以认为该特征是适用于大多数样本的“普遍规律”，所以倾向于保留它；反之是一些可能造成过拟合的无用特征，就倾向于减弱它对总体的影响。所以《Deep Learning》书中也提到：L2正则化能让学习算法“感知”到具有较高方差的输入x，因此与输出目标的协方差较小的特征的权重将会收缩。这里高方差的输入就是与其他样本差异性大的意思。
![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)


**L1正则化**
　　L1正则也被称为Lasso回归，形式如下：
J~(θ;X,y)=J(θ;X,y)+α∥w∥1(8)
现在按照分析L2正则的步骤分析一下L1正则的效果。(8)对应的梯度为：
∇wJ~(θ;X,y)=∇wJ(θ;X,y)+αsign(w)(9)
我们立刻可以发现，L1的正则化效果与L2大不一样。具体来说，L1正则化对梯度的影响不再是线性地缩放每个wi，而是添加了一项与sign(wi)同号的常数。这种形式的梯度不一定能得到直接算术解。
　　由于L1惩罚项在完全一般化的Hessian情况下，无法得到清晰的代数表达式。如果我们假设问题中的数据已被预处理（比如PCA），去除了输入特征之间的相关性，那么Hessian矩阵是对角的，即H=diag([H1,1,…,Hn,n])，其中每个Hi,i≥0。同式(5)一样对J(θ)进行二次泰勒展开近似，并将L1正则化目标函数的二次近似分解成关于参数的求和：
J~(w;X,y)=J(w;X,y)+α∥w∥1=J(w∗;X,y)+12(w−w∗)TH(w−w∗)+α∥w∥1=J(w∗;X,y)+∑i[12Hi,i(wi−w∗i)2+α|wi|]
下面形式的解析解可以最小化这近似代价函数：
wi=sign(w∗i)max{|w∗i|−αHi,i,0}(10)
对每个i，考虑w∗i>0的情况，会有两种可能的结果：
　　当w∗i≤αHi,i时，正则化中的wi最优值是0；
　　当w∗i>αHi,i时，正则化不会将wi的最优值推至0，而是在那个方向上移动αHi,i 的距离。
　　相比L2正则化，L1正则化会产生更稀疏的解。此处的稀疏性是指最优值中的一些参数为0。回顾式(7)，在L2正则化中，如果w∗i不为零，那么w~i也不为0，这表明L2正则化不会使参数变得稀疏，而L1正则化有可能通过足够大的α实现稀疏。L2是对那些与多数特征不同的分量进行衰减，而L1则是舍弃那些低于某个标准的特征。这种稀疏性广泛用于特征选择机制，可以从可用的特征子集中选择出有意义的特征，化简机器学习问题。
　　L1正则化可通过假设权重w的先验分布为拉普拉斯分布，由最大后验概率估计导出. 

**噪声注入**

　　模型容易过拟合的原因之一就是没有太好的抗噪能力，如果输入数据稍微改变一点点，就可能得到完全不一样的结果。正所谓“你害怕什么，就应该勇敢去面对什么”。最简单提高网络抗噪能力的方法，就是在训练中加入随机噪声一起训练。我们可以在网络的不同位置加入噪声：输入层，隐藏层，输出层。
　　数据集增强在某种意义上也能看做是在输入层加入噪声，通过随机旋转、翻转，色彩变换，裁剪等操作人工扩充训练集大小。这样可以使得网络对于输入更加鲁棒。
　　大名鼎鼎的Dropout方法属于在隐藏层中加入噪声的一种方式。这个因为比较重要，待会儿单独提出来讲。
　　对于输出层有人可能会有疑问，要知道我们手中数据集并不可能100%保证标记正确，多多少少总会有一点错误率的。当然如果你能保证数据集没错误，不向输出层加入噪声也没关系。解决这个问题常见的办法是标签平滑，通过把确切的分类目标从0和1替换成ϵk−1
和1−ϵ，正则化具有k

个输出的softmax函数的模型。标签平滑的优势是能够防止模型追求确切的概率而不能学习正确分类。
　　从优化过程的角度来看，对权重叠加方差极小噪声等价于对权重是假范数惩罚，可以被解释为关于权重的贝叶斯推断的随即实现（这一点我不是很理解）。换个角度就很结论就很明朗了，因为我们在权重中添加了一些随机扰动，这鼓励优化过程找到一个参数空间，该空间对微小参数变化引起的输出变化影像很小。将模型送入了一个对于微小变化不敏感的区域，不仅找到了最小值，还找到了一个宽扁的最小值区域。
  
**多任务学习**

　　多任务学习通过合并几个任务中的样例（可以视为对参数是假的软约束）来提高泛化的一种方式。正如为的训练样本能够将模型参数推向具有更好泛化能力的值一样，当模型的一部分被多个额外的任务共享时，这部分将被约束为良好的值（如果共享合理），通常会带来更好的泛化能力。![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)


**Dropout**

　　在介绍Dropout之前，先提一下集成学习Bagging的概念，即通过结合几个模型降低泛化误差的技术。分别训练几个不同的模型，然后让所有模型表决测试样例的输出，也被称为模型平均。模型平均奏效的原因是不同的模型通常不会再测试集上产生完全相同的误差。
　　假设我们有k
个回归模型，每个模型在每个例子上的误差为ϵi，这个误差服从均值为0，方差E[ϵ2i]=v且协方差E[ϵiϵj]=c的多维正态分布。通过所有集成模型的平均预测所得误差是1k∑iϵi

，则该集成预测期的平方误差的期望为：
E[(1k∑iϵi)2]=1k2E[∑i(ϵ2i+∑j≠iϵiϵj)]=1kv+k−1kc(11)
在误差完全相关即c=v的情况下，E[(1k∑iϵi)2]=v，模型平均对提升结果没有任何帮助；在误差完全不想关即c=0的情况下，集成模型的误差期望减少到E[(1k∑iϵi)2]=1kv。用一句话说，平均上，集成至少与它任何成员表现的一样好，并且如果成员误差是独立的，集成将显著地比其成员表现的更好。神经网络中随机初始化的差异、小批量的随机选择、超参数的差异或不同输出的非确定性实现往往足以使得集成中的不同成员具有部分独立的误差。
　　弄明白模型平均的优点后，我们再来看看Dropout。表面上看，Dropout是每次训练过程中随机舍弃一些神经元之间的连接，如下图所示。
![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

Dropout提供了一种廉价的Bagging集成近似，能够训练和评估指数级数量的神经网络。Dropout和Bagging训练不太一样，Bagging所有模型都是独立的，而Dropout是所有模型共享参数，每个模型集成父神经网络参数的不同子集，这中参数共享的方式使得在有限可用内存下表示指数级数量的模型变得可能。
　　隐藏单元经过Dropout训练后，它必须学习与不同采样神经元的合作，使得神经元具有更强的健壮性，并驱使神经元通过自身获取到有用的特征，而不是依赖其他神经元去纠正自身的错误。这可以看错对输入内容的信息高度智能化，自适应破坏的一种形式，而不是对输入原始值的破坏。
　　Dropout的另一个重要方面是噪声是乘性的。如果是固定规模的加性噪声，那么加了噪声ϵ的ReLU可以简单的学会使hi变得很大（使增加的噪声ϵ变得不显著）。乘性噪声就不允许这样病态的去解决噪声鲁棒问题。


**提前终止**

模型过拟合一般是发生在训练次数过多的情况下，那么只要我们在过拟合之前停止训练即可。这也是深度学习中最常用的正则化形式，主要是因为它的有效性和简单性。提前终止需要验证集损失作为观测指标，当验证集损失开始持续上升时，这时就该停止训练过程了。

### 优化

**一、学习与纯优化的区别：**
在机器学习问题中，为了优化某性能度量P，一般通过降低代价函数J(θ)来间接提高P；但纯优化是最小化目标J本身。

（1）经验风险最小化

“经验”是指在最小化训练误差时计算误差是用的训练集数据。
经验风险最小化容易导致过拟合，在deeplearing中很少使用。

（2）代理损失函数

是指损失函数很难优化求解时，将其进行一定的转化，用代理损失函数代替。
为了防止过拟合，通常会设置一定的收敛条件，让损失函数提前终止，因此训练停止时损失函数可能还有较大的导数，但纯优化终止时导数很小。

（3）批量/小批量（随机）算法

批量（batch）梯度算法：是指使用整个训练集的优化算法
小批量（mini-batch）随机梯度算法：指用训练集的一部分进行优化的算法。。。。在使用小批量梯度算法时随机抽取数据很重要。

**二、神经网络优化中的挑战**

（1）病态
是指随机梯度下降会卡在某个点，此时即使很小的更新步长也会增加代价函数。。
此问题在数值优化、凸优化中容易出现，牛顿法是解决该问题的方法之一。

（2）局部极小值
a.在凸优化问题中，它的底部有可能是一个平坦的区域，而不是单一的全局最小点，该区域的任何一个点都是可行解。
b.在非凸函数中，例如神经网络，可能会存在多个局部极小值。。
  神经网络具有权重空间对称性等问题导致的不可辨认性，所以很多局部极小值可能有相同的代价函数值，并且相比全局最小值拥有较大的代价。
  
（3）鞍点

鞍点附近的部分点比鞍点有更大代价，其他点有更小代价。
在低维空间，局部极小点很普遍；在高维空间，局部极小值罕见，但鞍点很常见。

（4）悬崖和梯度爆炸

多层神经网络存在斜率很大的区域。 在RNN中比较常见。
造成悬崖的原因是几个较大的权重相乘。
解决办法：悬崖截断 - 传统的梯度下降算法提议更新很大一步时，梯度截断会干涉来减小步长，从而使其不太可能走出悬崖区域。

（5）长期依赖：

是指由于变深的结构使模型丧失了学习到先前信息的能力，让优化变得极其困难，更多出现在RNN。
例如长期依赖导致的梯度消失（造成无法确定参数的移动方向）和梯度爆炸（造成学习很不稳定）。

**三、基本算法**
（1）随机梯度下降（SGD）
关键参数是学习率，且学习率是随时间减小。

（2）动量（momentum）/Nesterov动量
动量方法是加速学习，加快收敛速度，特别是处理高曲率、小但一致的梯度，或带噪声的梯度。
动量方法主要解决了Hessian矩阵的病态条件和随机梯度的方差。
步长从原来的【梯度范数乘以学习率】变成取决于【梯度序列的大小和排列】。
Nesterov动量是动量算法的变种。梯度计算施加在当前速度之后，即在标准动量方法中添加了一个校正因子。

**四、自适应学习率算法**
（1）Delta-bar-Delta算法
思路：如果损失对于某个给定模型参数的偏导保持相同的符号，则学习率增加；如果对于该参数的偏导变化了符号，则学习率减小。
只适用于全批量优化。

（2）AdaGrad算法
思路：缩放每一个参数反比于其所有梯度历史平方值总和的平方根
效果：在参数空间中更为平缓的倾斜方向会取得更大的进步
适用：适用于部分DNN。。但在某些DNN模型的训练中，从训练开始累积梯度平方导致有效学习率过早或过量地减小。

（3）RMSProp算法/ 结合Nesterov动量的RMSProp算法
思路：对AdaGrad算法进行改进，梯度累积变成了指数加权的移动平均。  ///越久的历史起的作用越小
比Adagrad算法更适用于非凸函数的训练。

（4）Adam算法
思路：动量直接并入了梯度一阶矩的估计；也包括了偏置修正，修正从原点初始化的一阶矩和二阶矩的估计。

**五、二阶近似方法**
一阶优化算法：仅使用梯度信息的优化算法
二阶优化算法：使用Hessian矩阵的优化算法

（1）牛顿法

思想：在现有极小点估计值的附近对f（x）做二阶泰勒展开，进而找到极小点的下一个估计值。
局限性：a. 牛顿法只适用于Hessian矩阵是正定的情况。但在大部分深度学习中，目标函数的表面是非凸的，因此为了使牛顿法仍然适用，可对Hessian矩阵进行正则化。
        b. 牛顿法中每次参数更新都需要求Hessian矩阵的逆，而Hessian矩阵的元素个数是参数个数K的平方，因此计算量会巨大。
        
（2）共轭梯度（conjugate directions）

通过迭代下降的共轭方向以有效避免Hessian矩阵求逆计算。  在共轭梯度法中，我们寻求一个和先前搜索方向共轭的搜索方向，即它不会撤销该方向上的进展。
在k维参数空间中，共轭梯度只需要至多k次线搜索就能达到极小值。

（3）拟牛顿法 —— BFGS算法/L-BFGS算法
拟牛顿法是采用矩阵Mt近似拟，迭代地低秩更新精度以更好近似H的逆。

**六、优化策略**
（1）批标准化
算法思路：标准化每个单元的均值和方差，以稳定化学习，但允许单元和单个单元的非线性统计量之间的关系发生变化。
          是一个自适应的重参数化的方法。重参数化显著减少多层之间协调更新的问题。可用于网络的任何输入层或隐藏层。
          
（2）坐标下降法
算法思路：先固定一部分变量，只优化一个或一部分变量，反复循环所有的变量，也可保证到达（局部）最小值。
适用：当优化问题中的不同变量能够分成相对独立的组，或是当优化一组变量明显比优化所有变量效率更高时，就用坐标下降法。
      当一个变量的值很大程度地影响另一个人变量的最优值时，不能使用坐标下降。（个人理解：固定的变量和优化的变量应该是独立的）
      
（3）Polyak平均
算法内容：平均优化算法在参数空间访问轨迹中的几个点。
基本想法：优化算法可能会来回穿过山谷好几次而没经过山谷底部附近的点，尽管两边所有位置的均值应比较接近谷底。

（4）监督预训练
算法思想：在直接训练目标模型求解目标问题之前，先训练简单模型求解简化问题。
可与贪心算法相结合形成贪心监督预训练。

（5）延拓法
算法思想：通过挑选初始点使优化更容易，以确保局部优化花费大部分时间在表现良好的空间。 
该算法是构造一系列具有相同参数的目标函数。这系列代价函数设计为前一个解是下一个的良好初始点。
优点：a.解决局部极小值问题。在有很多局部极小值的情况下，求解一个全局最小点。
      b.延拓法引入的简化目标函数能够消除平坦区域，减少梯度估计的方差，提高Hessian矩阵的条件数，使局部更新更容易计算。




